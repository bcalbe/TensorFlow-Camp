{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "labels = iris.target\n",
    "data = np.concatenate((data,labels.reshape(150,1)),axis=-1)\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[:,-1]\n",
    "X = data[:,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 备注X是特征，Y是label。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 序列模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##此处需定义模型\n",
    "#三种模型分别尝试\n",
    "model  = keras.Sequential()\n",
    "model.add(layers.Dense(64,activation = 'relu'))\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.Dense(3,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(4,))\n",
    "x1 = layers.Dense(64,activation = 'relu')(inputs)\n",
    "x2 = layers.Dense(256,activation = 'relu')(x1)\n",
    "predictions = layers.Dense(3,activation = 'softmax')(x2)\n",
    "model = keras.Model(inputs = inputs,outputs = predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类定义形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CNNModel,self).__init__()\n",
    "        self.dense_1 = layers.Dense(64,activation = 'relu')\n",
    "        self.dense_2 = layers.Dense(256,activation = 'relu')\n",
    "        self.dense_3 = layers.Dense(3,activation = 'softmax')\n",
    "\n",
    "    def call(self,inputs):\n",
    "        x1 = self.dense_1(inputs)\n",
    "        x2 = self.dense_2(x1)\n",
    "        outputs = self.dense_3(x2)\n",
    "        return outputs\n",
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 150 samples\nEpoch 1/100\n150/150 [==============================] - 0s 2ms/sample - loss: 0.0971 - sparse_categorical_accuracy: 0.9600\nEpoch 2/100\n150/150 [==============================] - 0s 106us/sample - loss: 0.1059 - sparse_categorical_accuracy: 0.9533\nEpoch 3/100\n150/150 [==============================] - 0s 115us/sample - loss: 0.0914 - sparse_categorical_accuracy: 0.9600\nEpoch 4/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0664 - sparse_categorical_accuracy: 0.9733\nEpoch 5/100\n150/150 [==============================] - 0s 127us/sample - loss: 0.0795 - sparse_categorical_accuracy: 0.9733\nEpoch 6/100\n150/150 [==============================] - 0s 126us/sample - loss: 0.0650 - sparse_categorical_accuracy: 0.9800\nEpoch 7/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0730 - sparse_categorical_accuracy: 0.9667\nEpoch 8/100\n150/150 [==============================] - 0s 126us/sample - loss: 0.0644 - sparse_categorical_accuracy: 0.9800\nEpoch 9/100\n150/150 [==============================] - 0s 107us/sample - loss: 0.0681 - sparse_categorical_accuracy: 0.9800\nEpoch 10/100\n150/150 [==============================] - 0s 126us/sample - loss: 0.0647 - sparse_categorical_accuracy: 0.9867\nEpoch 11/100\n150/150 [==============================] - 0s 126us/sample - loss: 0.0691 - sparse_categorical_accuracy: 0.9733\nEpoch 12/100\n150/150 [==============================] - 0s 106us/sample - loss: 0.0794 - sparse_categorical_accuracy: 0.9733\nEpoch 13/100\n150/150 [==============================] - 0s 133us/sample - loss: 0.1019 - sparse_categorical_accuracy: 0.9600\nEpoch 14/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0716 - sparse_categorical_accuracy: 0.9667\nEpoch 15/100\n150/150 [==============================] - 0s 153us/sample - loss: 0.0714 - sparse_categorical_accuracy: 0.9800\nEpoch 16/100\n150/150 [==============================] - 0s 133us/sample - loss: 0.0691 - sparse_categorical_accuracy: 0.9733\nEpoch 17/100\n150/150 [==============================] - 0s 133us/sample - loss: 0.0614 - sparse_categorical_accuracy: 0.9933\nEpoch 18/100\n150/150 [==============================] - 0s 146us/sample - loss: 0.0654 - sparse_categorical_accuracy: 0.9800\nEpoch 19/100\n150/150 [==============================] - 0s 146us/sample - loss: 0.0718 - sparse_categorical_accuracy: 0.9733\nEpoch 20/100\n150/150 [==============================] - 0s 133us/sample - loss: 0.0658 - sparse_categorical_accuracy: 0.9733\nEpoch 21/100\n150/150 [==============================] - 0s 140us/sample - loss: 0.0632 - sparse_categorical_accuracy: 0.9800\nEpoch 22/100\n150/150 [==============================] - 0s 133us/sample - loss: 0.0637 - sparse_categorical_accuracy: 0.9800\nEpoch 23/100\n150/150 [==============================] - 0s 119us/sample - loss: 0.0616 - sparse_categorical_accuracy: 0.9867\nEpoch 24/100\n150/150 [==============================] - 0s 133us/sample - loss: 0.0625 - sparse_categorical_accuracy: 0.9800\nEpoch 25/100\n150/150 [==============================] - 0s 140us/sample - loss: 0.0649 - sparse_categorical_accuracy: 0.9800\nEpoch 26/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0648 - sparse_categorical_accuracy: 0.9733\nEpoch 27/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0624 - sparse_categorical_accuracy: 0.9800\nEpoch 28/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0589 - sparse_categorical_accuracy: 0.9800\nEpoch 29/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0632 - sparse_categorical_accuracy: 0.9800\nEpoch 30/100\n150/150 [==============================] - 0s 153us/sample - loss: 0.0606 - sparse_categorical_accuracy: 0.9867\nEpoch 31/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0610 - sparse_categorical_accuracy: 0.9800\nEpoch 32/100\n150/150 [==============================] - 0s 106us/sample - loss: 0.0630 - sparse_categorical_accuracy: 0.9867\nEpoch 33/100\n 32/150 [=====>........................] - ETA: 0s - loss: 0.0681 - sparse_categorical_accuracy: 0.968150/150 [==============================] - 0s 120us/sample - loss: 0.0718 - sparse_categorical_accuracy: 0.9667\nEpoch 34/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0580 - sparse_categorical_accuracy: 0.9867\nEpoch 35/100\n150/150 [==============================] - 0s 146us/sample - loss: 0.0763 - sparse_categorical_accuracy: 0.9733\nEpoch 36/100\n150/150 [==============================] - 0s 140us/sample - loss: 0.0670 - sparse_categorical_accuracy: 0.9733\nEpoch 37/100\n150/150 [==============================] - 0s 133us/sample - loss: 0.0640 - sparse_categorical_accuracy: 0.9733\nEpoch 38/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0655 - sparse_categorical_accuracy: 0.9800\nEpoch 39/100\n150/150 [==============================] - 0s 140us/sample - loss: 0.0666 - sparse_categorical_accuracy: 0.9733\nEpoch 40/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0626 - sparse_categorical_accuracy: 0.9867\nEpoch 41/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0750 - sparse_categorical_accuracy: 0.9733\nEpoch 42/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0889 - sparse_categorical_accuracy: 0.9600\nEpoch 43/100\n150/150 [==============================] - 0s 133us/sample - loss: 0.0650 - sparse_categorical_accuracy: 0.9667\nEpoch 44/100\n150/150 [==============================] - 0s 180us/sample - loss: 0.0764 - sparse_categorical_accuracy: 0.9733\nEpoch 45/100\n150/150 [==============================] - 0s 133us/sample - loss: 0.0683 - sparse_categorical_accuracy: 0.9733\nEpoch 46/100\n150/150 [==============================] - 0s 146us/sample - loss: 0.0731 - sparse_categorical_accuracy: 0.9667\nEpoch 47/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0732 - sparse_categorical_accuracy: 0.9733\nEpoch 48/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0843 - sparse_categorical_accuracy: 0.9533\nEpoch 49/100\n150/150 [==============================] - 0s 106us/sample - loss: 0.0657 - sparse_categorical_accuracy: 0.9800\nEpoch 50/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0674 - sparse_categorical_accuracy: 0.9733\nEpoch 51/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0666 - sparse_categorical_accuracy: 0.9667\nEpoch 52/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0551 - sparse_categorical_accuracy: 0.9867\nEpoch 53/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0702 - sparse_categorical_accuracy: 0.9733\nEpoch 54/100\n150/150 [==============================] - 0s 126us/sample - loss: 0.0649 - sparse_categorical_accuracy: 0.9867\nEpoch 55/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0595 - sparse_categorical_accuracy: 0.9800\nEpoch 56/100\n150/150 [==============================] - 0s 126us/sample - loss: 0.0614 - sparse_categorical_accuracy: 0.9800\nEpoch 57/100\n150/150 [==============================] - 0s 133us/sample - loss: 0.0600 - sparse_categorical_accuracy: 0.9867\nEpoch 58/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0580 - sparse_categorical_accuracy: 0.9867\nEpoch 59/100\n150/150 [==============================] - 0s 140us/sample - loss: 0.0577 - sparse_categorical_accuracy: 0.9800\nEpoch 60/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0610 - sparse_categorical_accuracy: 0.9800\nEpoch 61/100\n150/150 [==============================] - 0s 126us/sample - loss: 0.0575 - sparse_categorical_accuracy: 0.9867\nEpoch 62/100\n150/150 [==============================] - 0s 140us/sample - loss: 0.0598 - sparse_categorical_accuracy: 0.9800\nEpoch 63/100\n150/150 [==============================] - 0s 126us/sample - loss: 0.0585 - sparse_categorical_accuracy: 0.9867\nEpoch 64/100\n150/150 [==============================] - 0s 126us/sample - loss: 0.0597 - sparse_categorical_accuracy: 0.9800\nEpoch 65/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0596 - sparse_categorical_accuracy: 0.9800\nEpoch 66/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0593 - sparse_categorical_accuracy: 0.9867\nEpoch 67/100\n150/150 [==============================] - 0s 133us/sample - loss: 0.0564 - sparse_categorical_accuracy: 0.9867\nEpoch 68/100\n150/150 [==============================] - 0s 140us/sample - loss: 0.0619 - sparse_categorical_accuracy: 0.9800\nEpoch 69/100\n150/150 [==============================] - 0s 126us/sample - loss: 0.0573 - sparse_categorical_accuracy: 0.9867\nEpoch 70/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0581 - sparse_categorical_accuracy: 0.9867\nEpoch 71/100\n150/150 [==============================] - 0s 140us/sample - loss: 0.0595 - sparse_categorical_accuracy: 0.9800\nEpoch 72/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0608 - sparse_categorical_accuracy: 0.9867\nEpoch 73/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0597 - sparse_categorical_accuracy: 0.9800\nEpoch 74/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0574 - sparse_categorical_accuracy: 0.9800\nEpoch 75/100\n150/150 [==============================] - 0s 106us/sample - loss: 0.0571 - sparse_categorical_accuracy: 0.9800\nEpoch 76/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0578 - sparse_categorical_accuracy: 0.9867\nEpoch 77/100\n150/150 [==============================] - 0s 126us/sample - loss: 0.0631 - sparse_categorical_accuracy: 0.9800\nEpoch 78/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0564 - sparse_categorical_accuracy: 0.9800\nEpoch 79/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0598 - sparse_categorical_accuracy: 0.9800\nEpoch 80/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0604 - sparse_categorical_accuracy: 0.9800\nEpoch 81/100\n150/150 [==============================] - 0s 106us/sample - loss: 0.0953 - sparse_categorical_accuracy: 0.9533\nEpoch 82/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0703 - sparse_categorical_accuracy: 0.9800\nEpoch 83/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0757 - sparse_categorical_accuracy: 0.9800\nEpoch 84/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0623 - sparse_categorical_accuracy: 0.9867\nEpoch 85/100\n150/150 [==============================] - 0s 126us/sample - loss: 0.0635 - sparse_categorical_accuracy: 0.9733\nEpoch 86/100\n150/150 [==============================] - 0s 118us/sample - loss: 0.0692 - sparse_categorical_accuracy: 0.9800\nEpoch 87/100\n150/150 [==============================] - 0s 133us/sample - loss: 0.0633 - sparse_categorical_accuracy: 0.9800\nEpoch 88/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0657 - sparse_categorical_accuracy: 0.9867\nEpoch 89/100\n150/150 [==============================] - 0s 140us/sample - loss: 0.0594 - sparse_categorical_accuracy: 0.9800\nEpoch 90/100\n150/150 [==============================] - 0s 180us/sample - loss: 0.0569 - sparse_categorical_accuracy: 0.9800\nEpoch 91/100\n150/150 [==============================] - 0s 146us/sample - loss: 0.0694 - sparse_categorical_accuracy: 0.9600\nEpoch 92/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0565 - sparse_categorical_accuracy: 0.9867\nEpoch 93/100\n150/150 [==============================] - 0s 100us/sample - loss: 0.0629 - sparse_categorical_accuracy: 0.9800\nEpoch 94/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0630 - sparse_categorical_accuracy: 0.9800\nEpoch 95/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0571 - sparse_categorical_accuracy: 0.9867\nEpoch 96/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0589 - sparse_categorical_accuracy: 0.9800\nEpoch 97/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0569 - sparse_categorical_accuracy: 0.9800\nEpoch 98/100\n150/150 [==============================] - 0s 120us/sample - loss: 0.0560 - sparse_categorical_accuracy: 0.9800\nEpoch 99/100\n150/150 [==============================] - 0s 113us/sample - loss: 0.0603 - sparse_categorical_accuracy: 0.9867\nEpoch 100/100\n150/150 [==============================] - 0s 126us/sample - loss: 0.0630 - sparse_categorical_accuracy: 0.9733\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x25fd0142848>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "####模型训练\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "#keras\n",
    "model.fit(X, Y, batch_size=32, epochs=100,shuffle=True,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python37764bittensorflowcondac03e494b497547649edc2d3deae885b3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}